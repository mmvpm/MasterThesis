\section{Применение на реальных микросервисных системах}

Для оценки практической применимости и эффективности разработанного инструмента был проведен его запуск на нескольких реальных микросервисных системах, разрабатываемых в Яндекс.Вертикалях. В данном разделе будут представлены итоги этого эксперимента, включая примеры реализованных архитектурных тестов и анализ полученных результатов. 

\subsection{Описание целевых систем}

Запуск инструмента проводился на четырех различных микросервисных системах, условно обозначенных как А, B, C и D. Все четыре системы представляют собой сложные, распределенные приложения внушительного масштаба:

\begin{itemize}
    \item \textbf{Система А}: включает в себя около 550 отдельных компонентов (микросервисы, базы данных, очереди сообщений и т.д.). 
    \item \textbf{Система B}: состоит из 300 компонентов. 
    \item \textbf{Система C}: насчитывает 400 компонентов. 
    \item \textbf{Система D}: включает 150 компонентов. 
\end{itemize}

Названия систем и точное число компонентов не приводятся в целях сохранения внутренней информации компании. Во всех последующих примерах названия конкретных сервисов также изменены по тем же соображениям.

Для лучшего понимания масштаба исследуемых систем отметим, что, по открытым данным, в 2023 году известный сервис Яндекс.Еда функционировал на основе около 180 различных микросервисов, то есть имел сопоставимые системам A-D размеры \cite{yandex-eda-ms-count}.

\subsection{Обнаруженные архитектурные антипаттерны}

В ходе эксперимента был реализован набор тестов и правил, нацеленных на выявление как общеизвестных архитектурных антипаттернов, так и нарушений специфичных для конкретных систем.

\subsubsection{Shared Database}

Антипаттерн Shared Database (Общая база данных) возникает, когда несколько независимых сервисов совместно используют одну и ту же базу данных. Разработанный тест проверяет, что каждая база данных используется не более чем одним сервисом или одной логической группой сервисов. Под логической группой подразумевается ситуация, когда один сервис физически разделён на несколько компонентов, например, когда API сервиса и его асинхронные задачи реализованы как разные развертываемые единицы. 

\begin{code}{scala}
"Each database" should {
  services
    .filter(_.isDatabase)
    .foreach { database =>
      s"be used by only one service: ${database.fqn}" in {
        val dependents = services
          .filter(_.hasDependencyOn(database))

        fromOneServiceGroup(dependents) shouldBe true
      }
    }
}
\end{code}

Вспомогательная функция \verb|fromOneServiceGroup| определяет принадлежность сервисов-потребителей к одной логической группе, например, по общему префиксу имени или другим метаданным. Конкретная реализация данной функции для краткости опущена.

Данный тест обнаружил 4 общие базы данных в системе A и по одной в системах B и D.

\subsubsection{Lava Flow}

Антипаттерн Lava Flow (Поток лавы) описывает накопление в системе устаревших и неиспользуемых компонентов. Это могут быть базы данных, сервисы или топики Kafka, на которые ни один другой компонент системы уже не зависит. 

Тест для поиска неиспользуемых баз данных:

\begin{code}{scala}
"Each database" should {
  services
    .filter(_.isDatabase)
    .foreach { database =>
      s"be used: ${database.fqn}" in {
        val dependents = services
          .filter(_.hasDependencyOn(database))

        dependents should not be empty
      }
    }
}
\end{code}

Тест для поиска неиспользуемых API-сервисов выглядит аналогично. Отметим, что проверять таким образом сервисы, которые не выставляют API, не имеет смысла, так как на них в принципе нельзя зависеть в рамках построенного графа.

\begin{code}{scala}
"Each API service" should {
  services
    .filter(_.isService)
    .filter(_.provides.nonEmpty) // provides some API
    .foreach { service =>
      s"be used: ${service.fqn}" in {
        val dependents = services
          .filter(_.hasDependencyOn(service))

        dependents should not be empty
      }
    }
}
\end{code}

С топиками Kafka ситуация несколько сложнее: тест должен проверить, что у каждого топика есть хотя бы один продюсер и хотя бы один консьюмер. Также необходимо учесть, что одна очередь сообщений (представленная как один компонент в графе зависимостей) может предоставлять несколько топиков, каждый из которых тест должен обработать отдельно. 

\begin{code}{scala}
"Each kafka topic" should {
  val topics = Services.Kafka.provides.map { topic =>
    // kafka with only one topic
    Services.Kafka.copy(provides = Seq(topic))
  }

  topics.foreach { topic =>
    val topicName = topic.provides.head.name.value

    s"have producer and consumer: $topicName" in {
      val dependents = services
        .filter(_.hasDependencyOn(topic))
      val producers = dependents
        .filter(_.isKafkaProducerFor(topicName))
      val consumers = dependents
        .filter(_.isKafkaConsumerFor(topicName))

      producers should not be empty
      consumers should not be empty
    }
  }
}
\end{code}

Вышеописанные тесты помогли обнаружить 29 неиспользуемых сервисов, 5 неиспользуемых баз данных и 28 Kafka-топиков без продюсера или консьюмера: 17 сервисов, 2 базы данных и 9 топиков в системе А; 4 сервиса и 6 топиков в системе B; 6 сервисов, 2 базы данных и 4 топика в системе C; 2 сервиса, 1 база данных и 9 топиков в системе D. 

Важно отметить, что не все из обнаруженных <<неиспользуемых>> компонентов действительно являются таковыми. Некоторые сервисы могут быть предназначены для внешних интеграций, и поэтому внутренние зависимости на них отсутствуют. Также несколько сервисов на момент запуска тестов находились в фазе активной разработки, поэтому формальные зависимости на них еще не были установлены, что, конечно, не является архитектурной проблемой. Более подробный анализ количества ложноположительных срабатываний будет сделан в конце данного раздела.

\subsubsection{Cyclic Dependency}

Антипаттерн Cyclic Dependency (Циклическая зависимость \cite{cyclic-dep-ap}) между компонентами усложняет развертывание, тестирование и общее понимание системы. Тест ниже находит двусторонние циклические зависимости (циклы длины 2).

\begin{code}{scala}
"Dependency graph" should {
  services.foreach { service =>
    s"not have 2-cycles with ${service.fqn}" in {
      val cycles = services.filter { other =>
        other.fqn != service.fqn &&
        service.hasDependencyOn(other) &&
        other.hasDependencyOn(service)
      }

      cycles shouldBe empty
    }
  }
}
\end{code}

Данный тест выявил 53 циклические зависимости в сумме по всем четырем исследуемым системам. 

\subsubsection{Inverted API Gateway Dependency}

Антипаттерн Inverted API Gateway Dependency \cite{api-gateway-pattern} возникает при некорректном использовании паттерна API Gateway, когда нижестоящие бэкенд-сервисы начинают зависеть от самого Gateway. 

\begin{code}{scala}
"Backend service" should {
  services
    .filter(Services.ApiGateway.hasDependencyOn)
    .foreach { dependency =>
      s"not depend on api gateway: ${dependency.fqn}" in {
        val misuseFound = dependency
          .hasDependencyOn(Services.ApiGateway)

        misuseFound shouldBe false
      }
    }
}
\end{code}

Этот тест обнаружил 12 нежелательных зависимостей на API Gateway в системе A и по 3 зависимости в системах C и D.

\subsubsection{Anti-Corruption Layer Violation}

Паттерн Anti-Corruption Layer (ACL) предполагает, что любая интеграция с внешней системой должна проходить через специально выделенный компонент-адаптер. Соответственно, прямая зависимость внутреннего сервиса на внешнюю систему в обход ACL будет являться нарушением этого принципа. 

\begin{code}{scala}
"only external-system-acl" should {
  "be allowed to depend on external-system" in {
    val externalSystem = ServicePattern
      .withHost("external.system.com")
    val dependents = services
      .filter(_.hasDependencyOn(externalSystem))
    
    dependents shouldBe Seq(Services.ExternalSystemAcl)
  }
}
\end{code}

Тесты такого типа не выявили нарушений в анализируемых системах. 

\subsubsection{Другие типовые антипаттерны}

Помимо подробно рассмотренных выше антипаттернов, были также реализованы тесты на ряд других распространенных архитектурных проблем. Ниже приведено их краткое описание:

\begin{itemize}
    \item \textbf{Distributed Monolith} \cite{distr-monolith-ap}. Тест находит клики в графе зависимостей, то есть такие подмножества сервисов, где каждый сервис связан с каждым другим сервисом в этом подмножестве. Такая структура является явным признаком распределённого монолита. 
    \item \textbf{Shared Cache}. Aналогично общей базе данных, тест проверяет, что любой используемый кэш (например, Redis) используется только одним сервисом или одной логической группой сервисов. 
    \item \textbf{Heterogeneous Database Dependencies}. Тест проверяет микросервисы на наличие у них одновременных зависимостей от нескольких различных типов SQL-баз данных (например, от MySQL и PostgreSQL одновременно). Такая ситуация может быть неоправданной и несколько усложняет эксплуатацию и поддержку соответствующего сервиса. 
    % \item \textbf{Test/Prod Environment Leakage}: тест находит случаи, когда тестовые и продовые инстансы одного микросервиса используют одну и ту же базу данных. Это может приводить к утечкам данных между окружениями.
    \item \textbf{API Gateway Bypass}. Tест обнаруживает прямые обращения от внешних клиентов к внутренним сервисам в обход API Gateway, что является нарушением паттерна API Gateway. 
    \item \textbf{Improper External Dependencies}. Тест выявляет зависимости на внешние системы у сервисов, которые для этого не предназначены (например, у внутренних сервисов бизнес-логики или у самого API Gateway).
    \item \textbf{Lack of ownership}. Используя метаинформацию о компонентах системы, предоставляемую Shiva, тест валидирует, что каждым сервисом владеет ровно одна команда или несколько команд, но только из одного бизнес-домена. 
\end{itemize}

\subsubsection{Проекто-специфичные правила}

Помимо общих антипаттернов, наиболее ценные и релевантные проверки часто возникают из специфических требований конкретной системы или домена. Большинство таких проверок укладываются в следующую классификацию:

\begin{itemize}
    \item \textbf{Ограничение входящих зависимостей}. От компонента \verb|А| могут зависеть только сервисы, удовлетворяющие определённому предикату (например, по имени, владельцу или другим метаданным из Shiva).
    \item \textbf{Ограничение исходящих зависимостей}. Сервис \verb|B| может обращаться только к компонентам (сервисам, базам данных, очередям сообщений и т.д.), соответствующим заданному предикату на основе их метаданных.
    \item \textbf{Контроль отсутствия зависимостей}. Сервис \verb|C| не должен обращаться к другим компонентам системы. Например, являясь прокси к внешней системе или простым сервисом с повышенными требованиями к производительности.
    \item \textbf{Явный запрет определённых зависимостей}. Прямой запрет на взаимодействие между двумя конкретными сервисами или даже между группами сервисов, где группы определяются предикатами, опять же, на основе метаинформации.
\end{itemize}

Разработанный инструмент позволяет гибко описывать такие проекто-специфичные правила как с помощью Scala-тестов, так и декларативно в YAML-конфигурациях. Причем заметим, что большинство шаблонных проверок могут быть выражены именно через YAML.

\subsection{Анализ результатов запуска}

\subsubsection{Сводные результаты}

Результаты запуска всех описанных выше тестов на четырех целевых системах представлены в таблице \ref{results-summary}. Каждая строка таблицы соответствует определенному типу найденного архитектурного нарушения, а столбцы отражают количество таких нарушений для каждой из систем A, B, C и D.

\begin{table}[ht]
\centering
\begin{tabular}{
    |l
    |>{\centering\arraybackslash}p{1.5cm}
    |>{\centering\arraybackslash}p{1.5cm}
    |>{\centering\arraybackslash}p{1.5cm}
    |>{\centering\arraybackslash}p{1.5cm}|
}
\hline
\textbf{Архитектурное нарушение} & \textbf{A} & \textbf{B} & \textbf{C} & \textbf{D} \\ \hline
Shared Database & 4 & 1 & 0 & 1 \\
Unused Database & 2 & 0 & 1 & 2 \\
Unused API Service & 17 & 4 & 6 & 2 \\
Unused Kafka Topic: No Producers & 4 & 2 & 0 & 3 \\
Unused Kafka Topic: No Consumers & 5 & 4 & 4 & 6 \\
Cyclic Dependency & 15 & 16 & 17 & 5 \\
Inverted API Gateway Dependency & 12 & 0 & 3 & 3 \\
Distributed Monolith & 2 & 2 & 1 & 1 \\
Shared Cache & 1 & 0 & 1 & 3 \\
Heterogeneous Database Dependencies & 2 & 0 & 2 & 1 \\
API Gateway Bypass & 11 & 0 & 8 & 1 \\
Improper External Dependencies & 4 & 3 & 9 & 10 \\
Custom check & 2 & 0 & 0 & 0 \\
Lack of ownership & 1 & 0 & 1 & 1 \\ \hline
\textbf{Итого} & \textbf{82} & \textbf{32} & \textbf{53} & \textbf{39} \\ \hline
\end{tabular}
\caption{\label{results-summary} Сводные результаты запуска тестов на системах A, B, C и D}
\end{table}

Как видно из таблицы \ref{results-summary}, для каждой из проанализированных систем было выявлено от нескольких десятков до почти сотни потенциальных архитектурных проблем различной степени критичности.

\subsubsection{Анализ ложных срабатываний}

Важно отметить, что определённый процент обнаруженных нарушений (по предварительным оценкам, около 8\%) может быть классифицирован как <<ложноположительные>> срабатывания. Причины таких срабатываний могут быть разнообразны. Основной источник — это неточности или неактуальность информации в конфигурационных файлах Shiva. Например, устаревшие записи в секции \verb|depends_on| или переменные окружения, больше не отражающие реальные зависимости. Конкретно в этом случае исправление падающего теста заключается в актуализации самих IaC-конфигураций, что само по себе является полезным процессом. Помимо этого ложные срабатывания могут возникать из-за не вполне корректно написанных или излишне строгих архитектурных правил, а также указывать на ограничения самого подхода, когда архитектура выводится исключительно из инфраструктурных артефактов. Таким образом, метрика ложноположительных срабатываний в данном контексте скорее отражает текущее состояние и культуру ведения IaC-артефактов в командах разработки, и в меньшей степени указывает на недостатки самого инструмента.

Стоит отдельно отметить, что инструмент намеренно спроектирован таким образом, чтобы можно было игнорировать ложные срабатывания без внесения изменений в код тестов. Например, уведомления в Telegram сообщают в первую очередь о новых или изменившихся архитектурных проблемах относительно базовой версии кода. То есть существующие упавшие тесты не будут постоянно беспокоить разработчиков.

\subsubsection{Ограничения используемого подхода}

Необходимо понимать, что предлагаемый подход, основанный на статическом анализе конфигурационных файлов и построении графа зависимостей, имеет свои ограничения. Не все типы архитектурных антипаттернов могут быть эффективно обнаружены таким способом. Например:
\begin{itemize}
    \item \textbf{Проблемы производительности}. Архитектурные решения, негативно влияющие на производительность системы (например, неэффективные запросы к базам данных, отсутствие кэширования в узких местах, проблема N+1 запросов), не могут быть выявлены исключительно на основе анализа статических конфигураций зависимостей.
    \item \textbf{Консистентность данных}. Проблемы, связанные с обеспечением согласованности данных между различными микросервисами, особенно если они не используют общие хранилища, сложно детектировать без глубокого анализа протоколов взаимодействия и логики обработки сообщений.
    \item \textbf{Сложные поведенческие антипаттерны}. Антипаттерны, которые проявляются в динамике во время выполнения системы (например, некорректная обработка ошибок, приводящая к каскадным сбоям, или неправильная реализация паттернов отказоустойчивости, таких как Circuit Breaker), требуют анализа логов, метрик выполнения или трассировок вызовов, а не только статических конфигураций.
\end{itemize}

\subsubsection{Выводы}

Разработанный инструмент был апробирован на четырёх реальных микросервисных системах, состоящих из сотен компонентов. В ходе этого эксперимента был реализован набор архитектурных тестов, нацеленных на выявление как общеизвестных антипаттернов, так и нарушений специфических правил конкретных систем. Применение инструмента позволило обнаружить значительное количество потенциальных архитектурных проблем в каждой из проанализированных систем. Таким образом, полученные результаты подтверждают практическую применимость реализованного инструмента к автоматизированному контролю качества архитектуры.
